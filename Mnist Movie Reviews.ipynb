{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 15s 982us/sample - loss: 0.5299 - binary_accuracy: 0.7983 - val_loss: 0.4151 - val_binary_accuracy: 0.8560\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 5s 363us/sample - loss: 0.3272 - binary_accuracy: 0.9025 - val_loss: 0.3146 - val_binary_accuracy: 0.8869\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2395 - binary_accuracy: 0.9229 - val_loss: 0.2821 - val_binary_accuracy: 0.8911\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 4s 244us/sample - loss: 0.1890 - binary_accuracy: 0.9389 - val_loss: 0.2765 - val_binary_accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 4s 248us/sample - loss: 0.1518 - binary_accuracy: 0.9531 - val_loss: 0.2784 - val_binary_accuracy: 0.8896\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 4s 242us/sample - loss: 0.1256 - binary_accuracy: 0.9615 - val_loss: 0.2851 - val_binary_accuracy: 0.8878\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 4s 241us/sample - loss: 0.1051 - binary_accuracy: 0.9683 - val_loss: 0.2991 - val_binary_accuracy: 0.8853\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 4s 245us/sample - loss: 0.0846 - binary_accuracy: 0.9768 - val_loss: 0.3174 - val_binary_accuracy: 0.8820\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 4s 241us/sample - loss: 0.0689 - binary_accuracy: 0.9831 - val_loss: 0.3499 - val_binary_accuracy: 0.8804\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 4s 244us/sample - loss: 0.0586 - binary_accuracy: 0.9859 - val_loss: 0.3631 - val_binary_accuracy: 0.8786\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 4s 243us/sample - loss: 0.0460 - binary_accuracy: 0.9891 - val_loss: 0.4140 - val_binary_accuracy: 0.8685\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 4s 241us/sample - loss: 0.0359 - binary_accuracy: 0.9924 - val_loss: 0.4099 - val_binary_accuracy: 0.8767\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 4s 242us/sample - loss: 0.0290 - binary_accuracy: 0.9948 - val_loss: 0.4397 - val_binary_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 4s 250us/sample - loss: 0.0245 - binary_accuracy: 0.9953 - val_loss: 0.4702 - val_binary_accuracy: 0.8735\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 4s 242us/sample - loss: 0.0179 - binary_accuracy: 0.9983 - val_loss: 0.4958 - val_binary_accuracy: 0.8756\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 4s 240us/sample - loss: 0.0151 - binary_accuracy: 0.9979 - val_loss: 0.5253 - val_binary_accuracy: 0.8730\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.0087 - binary_accuracy: 0.9997 - val_loss: 0.5660 - val_binary_accuracy: 0.8698\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 4s 255us/sample - loss: 0.0106 - binary_accuracy: 0.9983 - val_loss: 0.5977 - val_binary_accuracy: 0.8705\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 4s 244us/sample - loss: 0.0049 - binary_accuracy: 0.9998 - val_loss: 0.6439 - val_binary_accuracy: 0.8660\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 4s 263us/sample - loss: 0.0063 - binary_accuracy: 0.9988 - val_loss: 0.6610 - val_binary_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model With 16 Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 27s 1ms/sample - loss: 0.4479 - acc: 0.8245\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 190us/sample - loss: 0.2572 - acc: 0.9071\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 178us/sample - loss: 0.1986 - acc: 0.9303\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 171us/sample - loss: 0.1640 - acc: 0.9417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158c01a6e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 7s 264us/sample - loss: 0.4584 - acc: 0.8707\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test) #overfitting 6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model With 512 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 99s 4ms/sample - loss: 0.4671 - acc: 0.7919\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 15s 609us/sample - loss: 0.2158 - acc: 0.9136\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 16s 620us/sample - loss: 0.1298 - acc: 0.9518\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 15s 587us/sample - loss: 0.0596 - acc: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158b02e3b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 6s 229us/sample - loss: 0.4584 - acc: 0.8707\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test) #overfitting 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with 4 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 45s 2ms/sample - loss: 0.6031 - acc: 0.6852\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 6s 247us/sample - loss: 0.5038 - acc: 0.8271\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 6s 230us/sample - loss: 0.4534 - acc: 0.8800\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 6s 224us/sample - loss: 0.4179 - acc: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158a7878ac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 7s 265us/sample - loss: 0.4584 - acc: 0.8707\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)  # overfitting only 3%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
